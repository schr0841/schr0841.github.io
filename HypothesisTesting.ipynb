{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Scenario 1: Coin Flip Experiment (Testing for Fairness) ---\n",
    "\n",
    "def plot_coin_flip_simulation(num_experiments=1000, num_flips_per_experiment=100, true_p_heads=0.5, h0_p_heads=0.5, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Simulates coin flip experiments and plots the distribution of observed head proportions.\n",
    "\n",
    "    Illustrates:\n",
    "    - Null Hypothesis (H0): The coin is fair (p_heads = h0_p_heads).\n",
    "    - Alternative Hypothesis (Ha): The coin is not fair (p_heads != h0_p_heads).\n",
    "    - Type I Error: Rejecting H0 when it's true. Visually, this would be observing a\n",
    "      sample proportion in the \"tails\" of the distribution if H0 were true.\n",
    "    - Type II Error: Failing to reject H0 when it's false (i.e., Ha is true).\n",
    "      If true_p_heads is different from h0_p_heads, the distribution will be centered\n",
    "      elsewhere, and we can see the overlap with the H0 acceptance region.\n",
    "    \"\"\"\n",
    "    observed_proportions = []\n",
    "    for _ in range(num_experiments):\n",
    "        flips = np.random.rand(num_flips_per_experiment) < true_p_heads\n",
    "        observed_proportions.append(np.mean(flips))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(observed_proportions, bins=30, density=True, alpha=0.7, label=f'Simulated Proportions (True p={true_p_heads})')\n",
    "\n",
    "    # Distribution under H0\n",
    "    # Using normal approximation for the sampling distribution of the proportion\n",
    "    # Mean = p, SD = sqrt(p(1-p)/n)\n",
    "    h0_sd = np.sqrt(h0_p_heads * (1 - h0_p_heads) / num_flips_per_experiment)\n",
    "    x = np.linspace(h0_p_heads - 4*h0_sd, h0_p_heads + 4*h0_sd, 500)\n",
    "    h0_dist = stats.norm.pdf(x, h0_p_heads, h0_sd)\n",
    "    plt.plot(x, h0_dist, 'r--', label=f'Expected Dist. if H0 is True (p={h0_p_heads})')\n",
    "\n",
    "    plt.axvline(h0_p_heads, color='red', linestyle='-', linewidth=2, label=f'H0: p = {h0_p_heads}')\n",
    "\n",
    "    # Critical regions for Type I error if H0 is true\n",
    "    # Two-tailed test\n",
    "    lower_crit = stats.norm.ppf(alpha/2, loc=h0_p_heads, scale=h0_sd)\n",
    "    upper_crit = stats.norm.ppf(1 - alpha/2, loc=h0_p_heads, scale=h0_sd)\n",
    "    plt.axvline(lower_crit, color='orange', linestyle=':', linewidth=2, label=f'Lower Critical Value (alpha={alpha})')\n",
    "    plt.axvline(upper_crit, color='orange', linestyle=':', linewidth=2, label=f'Upper Critical Value (alpha={alpha})')\n",
    "    plt.fill_between(x, 0, h0_dist, where=(x <= lower_crit) | (x >= upper_crit), color='orange', alpha=0.3, label='Type I Error Region if H0 True')\n",
    "\n",
    "\n",
    "    plt.title('Coin Flip Experiment Simulation')\n",
    "    plt.xlabel('Proportion of Heads in Sample')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Scenario 1: Coin Flip Experiment\n",
    "    H0: The coin is fair (p_heads = {h0_p_heads}).\n",
    "    Ha: The coin is not fair (p_heads != {h0_p_heads}).\n",
    "    This plot shows the distribution of sample proportions from {num_experiments} simulated experiments.\n",
    "    - If the true probability of heads (true_p_heads) is {true_p_heads}, the histogram will be centered around this value.\n",
    "    - The red dashed line shows the expected distribution if the Null Hypothesis (coin is fair at p={h0_p_heads}) were true.\n",
    "    - The orange dotted lines mark critical values for a significance level of alpha={alpha}. If an observed proportion falls\n",
    "      outside these lines, we might reject H0.\n",
    "    - Type I Error (False Positive): If H0 is true (coin is fair) but our sample proportion by chance falls in the orange shaded regions,\n",
    "      we would incorrectly reject H0. The area of these orange regions under the red H0 curve represents alpha.\n",
    "    - Type II Error (False Negative): If H0 is false (e.g., true_p_heads = 0.6, but H0 assumes 0.5), but our sample proportion\n",
    "      by chance falls within the critical values (between the orange lines), we would incorrectly fail to reject H0.\n",
    "      This is more likely if the true effect is small or sample size is low.\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe0d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 2: Website A/B Test (Comparing Conversion Rates) ---\n",
    "\n",
    "def plot_ab_test_simulation(mean_A=0.10, std_A=0.03, n_A=1000, mean_B=0.12, std_B=0.035, n_B=1000, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Simulates and plots the sampling distributions for conversion rates of two website designs.\n",
    "\n",
    "    Illustrates:\n",
    "    - Null Hypothesis (H0): New design B is not better than A (mean_B <= mean_A).\n",
    "      For simplicity in visualization of errors, often visualized as mean_B = mean_A.\n",
    "    - Alternative Hypothesis (Ha): New design B is better than A (mean_B > mean_A).\n",
    "    - Type I Error: Concluding B is better when it's not (rejecting H0 when H0 is true).\n",
    "    - Type II Error: Failing to conclude B is better when it actually is (failing to reject H0 when Ha is true).\n",
    "    \"\"\"\n",
    "    # Sampling distributions (Normal approximation)\n",
    "    # Assuming H0: mean_A = mean_B. For visualization, let's assume for H0 that mean_B_under_H0 = mean_A\n",
    "    # And for Ha, mean_B_under_Ha = mean_B (the true mean_B if there is an effect)\n",
    "\n",
    "    # Distribution of sample mean for A\n",
    "    se_A = std_A / np.sqrt(n_A)\n",
    "    # x_A = np.linspace(mean_A - 4*se_A, mean_A + 4*se_A, 500) # Not directly plotted, but used in difference\n",
    "    # dist_A = stats.norm.pdf(x_A, mean_A, se_A)\n",
    "\n",
    "    # Distribution of sample mean for B *IF H0 IS TRUE* (i.e., mean_B = mean_A)\n",
    "    mean_B_h0 = mean_A\n",
    "    se_B_h0 = std_B / np.sqrt(n_B) # Using actual std_B for spread, but mean_A for center under H0\n",
    "    # x_B_h0 = np.linspace(mean_B_h0 - 4*se_B_h0, mean_B_h0 + 4*se_B_h0, 500) # Not directly plotted\n",
    "    # dist_B_h0 = stats.norm.pdf(x_B_h0, mean_B_h0, se_B_h0)\n",
    "\n",
    "\n",
    "    # Distribution of sample mean for B *IF Ha IS TRUE* (i.e., mean_B is its actual value, different from mean_A)\n",
    "    se_B_ha = std_B / np.sqrt(n_B)\n",
    "    # x_B_ha = np.linspace(mean_B - 4*se_B_ha, mean_B + 4*se_B_ha, 500) # Not directly plotted\n",
    "    # dist_B_ha = stats.norm.pdf(x_B_ha, mean_B, se_B_ha)\n",
    "\n",
    "    # For hypothesis testing, we look at the difference in means: D = mean_B - mean_A\n",
    "    # H0: D_h0 = 0\n",
    "    # Ha: D_ha = mean_B - mean_A\n",
    "    mean_diff_h0 = 0\n",
    "    std_diff_h0 = np.sqrt(se_A**2 + se_B_h0**2)\n",
    "\n",
    "    mean_diff_ha = mean_B - mean_A\n",
    "    std_diff_ha = np.sqrt(se_A**2 + se_B_ha**2)\n",
    "\n",
    "    x_diff_min = min(mean_diff_h0 - 4*std_diff_h0, mean_diff_ha - 4*std_diff_ha)\n",
    "    x_diff_max = max(mean_diff_h0 + 4*std_diff_h0, mean_diff_ha + 4*std_diff_ha)\n",
    "    # Ensure x_diff_min is not excessively far if one distribution is very narrow or means are very close\n",
    "    if mean_diff_ha == mean_diff_h0: # Handle case where H0 is true for plotting\n",
    "        x_diff_min = mean_diff_h0 - 4*std_diff_h0\n",
    "        x_diff_max = mean_diff_h0 + 4*std_diff_h0\n",
    "\n",
    "\n",
    "    x_diff = np.linspace(x_diff_min, x_diff_max, 500)\n",
    "\n",
    "    dist_diff_h0 = stats.norm.pdf(x_diff, mean_diff_h0, std_diff_h0)\n",
    "    dist_diff_ha = stats.norm.pdf(x_diff, mean_diff_ha, std_diff_ha)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(x_diff, dist_diff_h0, label=f'Dist. of (Mean B - Mean A) if H0 is True (No Difference)', color='blue')\n",
    "    plt.plot(x_diff, dist_diff_ha, label=f'Dist. of (Mean B - Mean A) if Ha is True (Actual Diff = {mean_diff_ha:.3f})', color='green', linestyle='--')\n",
    "\n",
    "    # Critical value for one-tailed test\n",
    "    critical_value = stats.norm.ppf(1 - alpha, loc=mean_diff_h0, scale=std_diff_h0)\n",
    "    plt.axvline(critical_value, color='red', linestyle=':', linewidth=2, label=f'Critical Value (alpha={alpha})')\n",
    "\n",
    "    # Type I Error region (alpha)\n",
    "    plt.fill_between(x_diff, 0, dist_diff_h0, where=x_diff >= critical_value, color='red', alpha=0.2, label='Type I Error Region (alpha)')\n",
    "\n",
    "    # Type II Error region (beta)\n",
    "    # This is the area under the Ha curve to the left of the critical value\n",
    "    if mean_diff_ha > mean_diff_h0 : # Only makes sense if Ha predicts a positive difference\n",
    "        beta_area = stats.norm.cdf(critical_value, loc=mean_diff_ha, scale=std_diff_ha)\n",
    "        plt.fill_between(x_diff, 0, dist_diff_ha, where=x_diff <= critical_value, color='purple', alpha=0.3, label=f'Type II Error Region (beta = {beta_area:.2f})')\n",
    "\n",
    "    plt.title('A/B Test Simulation: Sampling Distributions of Difference in Means')\n",
    "    plt.xlabel('Difference in Conversion Rates (Mean B - Mean A)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.axvline(0, color='black', linestyle='-', linewidth=1, label='No difference line') # Centered line\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Scenario 2: Website A/B Test (Conversion Rates)\n",
    "    H0: New design B is not better than A (mean_B - mean_A <= 0). (Simplified to mean_B - mean_A = 0 for visualization of H0 distribution)\n",
    "    Ha: New design B is better than A (mean_B - mean_A > 0).\n",
    "    This plot shows the sampling distributions of the *difference* in conversion rates between Design B and Design A.\n",
    "    - The blue curve represents the distribution of differences if H0 is true (no real difference in means).\n",
    "    - The green dashed curve represents the distribution of differences if Ha is true (Design B is truly better by {mean_B-mean_A:.3f}).\n",
    "    - The red dotted line is the critical value. If our observed difference is to the right of this, we reject H0.\n",
    "    - Type I Error (alpha, red shaded area): If H0 is true (no difference), this is the probability of observing a sample difference\n",
    "      large enough to (wrongly) conclude B is better.\n",
    "    - Type II Error (beta, purple shaded area): If Ha is true (B is actually better), this is the probability of observing a sample\n",
    "      difference too small to detect the improvement, so we (wrongly) fail to reject H0.\n",
    "      The power of the test is 1 - beta.\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94724e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Scenario 3: Drug Efficacy Test (Comparing Drug to Placebo) ---\n",
    "\n",
    "def plot_drug_efficacy_simulation(n_drug=50, mean_effect_drug=0.5, std_drug=0.2,\n",
    "                                  n_placebo=50, mean_effect_placebo=0.2, std_placebo=0.18,\n",
    "                                  alpha=0.05):\n",
    "    \"\"\"\n",
    "    Simulates outcomes for a drug group and a placebo group and plots them using box plots.\n",
    "\n",
    "    Illustrates:\n",
    "    - Null Hypothesis (H0): The drug has no effect compared to placebo (mean_drug <= mean_placebo).\n",
    "      Simplified to mean_drug = mean_placebo for visualization.\n",
    "    - Alternative Hypothesis (Ha): The drug has a positive effect (mean_drug > mean_placebo).\n",
    "    - How sample variability can make it hard to distinguish true effects.\n",
    "    - Visual intuition for comparing two groups.\n",
    "    \"\"\"\n",
    "    drug_outcomes = np.random.normal(loc=mean_effect_drug, scale=std_drug, size=n_drug)\n",
    "    placebo_outcomes = np.random.normal(loc=mean_effect_placebo, scale=std_placebo, size=n_placebo)\n",
    "\n",
    "    data_to_plot = [placebo_outcomes, drug_outcomes]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bp = plt.boxplot(data_to_plot, patch_artist=True, labels=['Placebo Group', 'Drug Group'])\n",
    "\n",
    "    colors = ['lightblue', 'lightgreen']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    # Add means to the plot\n",
    "    plt.scatter([1, 2], [np.mean(placebo_outcomes), np.mean(drug_outcomes)], color=['blue', 'green'], marker='o', s=100, zorder=3, label='Sample Means')\n",
    "\n",
    "\n",
    "    plt.title('Drug Efficacy Simulation: Outcomes by Group')\n",
    "    plt.ylabel('Symptom Reduction Score (Higher is Better)')\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # For hypothesis testing with these samples:\n",
    "    t_stat, p_value = stats.ttest_ind(drug_outcomes, placebo_outcomes, equal_var=False, alternative='greater') # Welch's t-test\n",
    "\n",
    "    print(f\"\"\"\n",
    "    Scenario 3: Drug Efficacy Test\n",
    "    H0: The drug has no greater effect than placebo (mean_drug_effect <= mean_placebo_effect).\n",
    "    Ha: The drug has a greater effect than placebo (mean_drug_effect > mean_placebo_effect).\n",
    "    This plot shows box plots of simulated symptom reduction scores for a placebo group and a drug group.\n",
    "    - Each box represents the distribution of outcomes for that group (median, quartiles, range).\n",
    "    - The 'o' markers indicate the sample means.\n",
    "    - Visual Overlap: If the boxes overlap significantly, it suggests that while the means might differ,\n",
    "      it's harder to be certain the drug is truly better due to variability in patient responses.\n",
    "    - Type I Error: If the drug actually has no added benefit (H0 is true), but due to random chance our samples\n",
    "      show a large enough difference (e.g., p-value < {alpha} from a t-test), we'd incorrectly conclude the drug is effective.\n",
    "      (Here, the actual t-test resulted in p-value={p_value:.3f})\n",
    "    - Type II Error: If the drug is truly effective (Ha is true), but our samples don't show a statistically significant\n",
    "      difference (e.g., p-value >= {alpha}), we'd fail to recognize its benefit. This is more likely with small\n",
    "      sample sizes or small true effects.\n",
    "    The box plots give an intuitive feel for the data before a formal test. A formal test (like a t-test) would\n",
    "    quantify the evidence against H0. If p-value ({p_value:.3f}) < alpha ({alpha}), we would reject H0.\n",
    "    \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0905ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate the plots and explanations ---\n",
    "# You would typically call these one at a time in an interactive environment\n",
    "# or save them to files if running as a script.\n",
    "\n",
    "# print(\"--- Running Scenario 1: Coin Flip ---\")\n",
    "# plot_coin_flip_simulation(true_p_heads=0.5) # Example where H0 is true\n",
    "# plot_coin_flip_simulation(true_p_heads=0.6, h0_p_heads=0.5) # Example where H0 is false\n",
    "\n",
    "# print(\"\\n--- Running Scenario 2: A/B Test ---\")\n",
    "# plot_ab_test_simulation(mean_A=0.10, mean_B=0.10) # Example where H0 is true (no difference)\n",
    "# plot_ab_test_simulation(mean_A=0.10, mean_B=0.13) # Example where H0 is false (B is better)\n",
    "\n",
    "# print(\"\\n--- Running Scenario 3: Drug Efficacy ---\")\n",
    "# plot_drug_efficacy_simulation(mean_effect_drug=0.25, mean_effect_placebo=0.20) # Example with a small true effect\n",
    "# plot_drug_efficacy_simulation(mean_effect_drug=0.5, mean_effect_placebo=0.2) # Example with a larger true effect\n",
    "# plot_drug_efficacy_simulation(mean_effect_drug=0.2, mean_effect_placebo=0.2) # Example where H0 is effectively true\n",
    "\n",
    "# To make this runnable by the execution environment and provide one example output for the user,\n",
    "# I will call one of the functions. Let's choose the first one with H0 being true.\n",
    "# The user can then uncomment other calls to explore.\n",
    "\n",
    "print(\"--- Visualizing Scenario 1: Coin Flip Experiment (H0 is True) ---\")\n",
    "plot_coin_flip_simulation(true_p_heads=0.5, h0_p_heads=0.5, num_experiments=500, num_flips_per_experiment=50)\n",
    "\n",
    "print(\"\\n--- Visualizing Scenario 2: A/B Test (H0 is True, No real difference) ---\")\n",
    "plot_ab_test_simulation(mean_A=0.10, mean_B=0.10, n_A=500, n_B=500) # H0 true\n",
    "\n",
    "print(\"\\n--- Visualizing Scenario 3: Drug Efficacy (Small true effect) ---\")\n",
    "plot_drug_efficacy_simulation(mean_effect_drug=0.25, mean_effect_placebo=0.20, n_drug=30, n_placebo=30)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
